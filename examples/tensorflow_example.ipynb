{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from typing import Union, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from src.optimizers.optimizer import HpOptimizer\n",
    "from src.parameter_generators.random_search import RandomHpSearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "    \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "    return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "def get_tf_mnist_dataset(**kwargs):\n",
    "    # https://www.tensorflow.org/datasets/keras_example\n",
    "    (ds_train, ds_test), ds_info = tfds.load(\n",
    "        'mnist',\n",
    "        split=['train', 'test'],\n",
    "        shuffle_files=True,\n",
    "        as_supervised=True,\n",
    "        with_info=True,\n",
    "    )\n",
    "\n",
    "    # Build training pipeline\n",
    "    ds_train = ds_train.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    ds_train = ds_train.cache()\n",
    "    ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "    ds_train = ds_train.batch(128)\n",
    "    ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    # Build evaluation pipeline\n",
    "    ds_test = ds_test.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    ds_test = ds_test.batch(128)\n",
    "    ds_test = ds_test.cache()\n",
    "    ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return ds_train, ds_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def get_tf_mnist_model(**hp):\n",
    "\n",
    "    if hp.get(\"use_conv\"):\n",
    "        model = tf.keras.models.Sequential([\n",
    "            # Convolution layers\n",
    "            tf.keras.layers.Conv2D(10, 3, padding=\"same\", input_shape=(1, 28, 28)),\n",
    "            tf.keras.layers.MaxPool2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(50, 3, padding=\"same\"),\n",
    "            tf.keras.layers.MaxPool2D((2, 2)),\n",
    "\n",
    "            # Dense layers\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(120, activation='relu'),\n",
    "            tf.keras.layers.Dense(84, activation='relu'),\n",
    "            tf.keras.layers.Dense(10)\n",
    "        ])\n",
    "    else:\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(120, activation='relu'),\n",
    "            tf.keras.layers.Dense(84, activation='relu'),\n",
    "            tf.keras.layers.Dense(10)\n",
    "        ])\n",
    "\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class KerasMNISTHpOptimizer(HpOptimizer):\n",
    "    def build_model(self, **hp) -> tf.keras.Model:\n",
    "        model = get_tf_mnist_model(**hp)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.SGD(\n",
    "                learning_rate=hp.get(\"learning_rate\", 1e-3),\n",
    "                nesterov=hp.get(\"nesterov\", True),\n",
    "                momentum=hp.get(\"momentum\", 0.99),\n",
    "            ),\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def fit_dataset_model_(\n",
    "            self,\n",
    "            model: tf.keras.Model,\n",
    "            dataset,\n",
    "            **hp\n",
    "    ) -> tf.keras.Model:\n",
    "        history = model.fit(\n",
    "            dataset,\n",
    "            epochs=hp.get(\"epochs\", 1),\n",
    "            verbose=False,\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def score(\n",
    "            self,\n",
    "            model: tf.keras.Model,\n",
    "            X: Union[np.ndarray, pd.DataFrame, tf.Tensor],\n",
    "            y: Union[np.ndarray, tf.Tensor],\n",
    "            **hp\n",
    "    ) -> Tuple[float, float]:\n",
    "        test_loss, test_acc = model\n",
    "        return test_acc/100, 0.0\n",
    "\n",
    "    def score_on_dataset(\n",
    "            self,\n",
    "            model: tf.keras.Model,\n",
    "            dataset,\n",
    "            **hp\n",
    "    ) -> Tuple[float, float]:\n",
    "        test_loss, test_acc = model.evaluate(dataset, verbose=0)\n",
    "        return test_acc, 0.0\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?itr/s, optimisation]ERROR:root:Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,28,10].\n",
      "ERROR:root:Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,28,10].\n",
      "  0%|          | 0/1000 [00:00<?, ?itr/s, optimisation]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,28,10].",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "\u001B[1;32md:\\github\\automlpy\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001B[0m in \u001B[0;36m_create_c_op\u001B[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001B[0m\n\u001B[0;32m   1852\u001B[0m   \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1853\u001B[1;33m     \u001B[0mc_op\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpywrap_tf_session\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTF_FinishOperation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mop_desc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1854\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mInvalidArgumentError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,28,10].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-10-e166142cb387>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     17\u001B[0m )\n\u001B[0;32m     18\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 19\u001B[1;33m param_gen = mnist_hp_optimizer.optimize_on_dataset(\n\u001B[0m\u001B[0;32m     20\u001B[0m     \u001B[0mparam_gen\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmnist_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msave_kwargs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msave_kwargs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m )\n",
      "\u001B[1;32mD:\\Github\\AutoMLpy\\src\\optimizers\\optimizer.py\u001B[0m in \u001B[0;36moptimize_on_dataset\u001B[1;34m(self, param_gen, dataset, nb_workers, save_kwargs, verbose, **kwargs)\u001B[0m\n\u001B[0;32m    356\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mee\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    357\u001B[0m                 \u001B[0mlogging\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0merror\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mee\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 358\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mee\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    359\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    360\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Github\\AutoMLpy\\src\\optimizers\\optimizer.py\u001B[0m in \u001B[0;36moptimize_on_dataset\u001B[1;34m(self, param_gen, dataset, nb_workers, save_kwargs, verbose, **kwargs)\u001B[0m\n\u001B[0;32m    348\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    349\u001B[0m                 \u001B[0mworkers_required\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnb_workers\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmax_itr\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 350\u001B[1;33m                 \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_process_trial_on_dataset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mparam_gen\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdataset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mworkers_required\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    351\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    352\u001B[0m                 stop_criterion_trigger = self._post_process_trial_(\n",
      "\u001B[1;32mD:\\Github\\AutoMLpy\\src\\optimizers\\optimizer.py\u001B[0m in \u001B[0;36m_process_trial_on_dataset\u001B[1;34m(self, param_gen, dataset, workers_required)\u001B[0m\n\u001B[0;32m    386\u001B[0m             \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_execute_multiple_param_gen_iteration_on_dataset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mworkers_required\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparam_gen\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdataset\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    387\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 388\u001B[1;33m             \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_execute_param_gen_iteration_on_dataset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mparam_gen\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdataset\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    389\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0moutputs\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    390\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Github\\AutoMLpy\\src\\optimizers\\optimizer.py\u001B[0m in \u001B[0;36m_execute_param_gen_iteration_on_dataset\u001B[1;34m(self, param_gen, dataset)\u001B[0m\n\u001B[0;32m    596\u001B[0m         \"\"\"\n\u001B[0;32m    597\u001B[0m         \u001B[0mparams\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mparam_gen\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_trial_param\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 598\u001B[1;33m         \u001B[0mmean_score\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_try_params_on_dataset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdataset\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    599\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmean_score\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    600\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Github\\AutoMLpy\\src\\optimizers\\optimizer.py\u001B[0m in \u001B[0;36m_try_params_on_dataset\u001B[1;34m(self, params, dataset)\u001B[0m\n\u001B[0;32m    632\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    633\u001B[0m                 \u001B[0mlogging\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0merror\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 634\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    635\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    636\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mmean_score\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Github\\AutoMLpy\\src\\optimizers\\optimizer.py\u001B[0m in \u001B[0;36m_try_params_on_dataset\u001B[1;34m(self, params, dataset)\u001B[0m\n\u001B[0;32m    625\u001B[0m                 \u001B[0msub_dataset_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msub_dataset_test\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_take_sub_dataset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    626\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 627\u001B[1;33m                 \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbuild_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    628\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit_dataset_model_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msub_dataset_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    629\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-9-1ae66d9747a0>\u001B[0m in \u001B[0;36mbuild_model\u001B[1;34m(self, **hp)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mKerasMNISTHpOptimizer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mHpOptimizer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mbuild_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mhp\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mModel\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m         \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_tf_mnist_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mhp\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m         model.compile(\n",
      "\u001B[1;32m<ipython-input-8-f9af0c5ec77b>\u001B[0m in \u001B[0;36mget_tf_mnist_model\u001B[1;34m(**hp)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mhp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"use_conv\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m         model = tf.keras.models.Sequential([\n\u001B[0m\u001B[0;32m      5\u001B[0m             \u001B[1;31m# Convolution layers\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m             \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mConv2D\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpadding\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"same\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_shape\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m28\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m28\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\github\\automlpy\\venv\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001B[0m in \u001B[0;36m_method_wrapper\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    515\u001B[0m     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_self_setattr_tracking\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    516\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 517\u001B[1;33m       \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    518\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    519\u001B[0m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_self_setattr_tracking\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mprevious_value\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\github\\automlpy\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, layers, name)\u001B[0m\n\u001B[0;32m    142\u001B[0m         \u001B[0mlayers\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mlayers\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    143\u001B[0m       \u001B[1;32mfor\u001B[0m \u001B[0mlayer\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mlayers\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 144\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlayer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    145\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    146\u001B[0m   \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\github\\automlpy\\venv\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001B[0m in \u001B[0;36m_method_wrapper\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    515\u001B[0m     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_self_setattr_tracking\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    516\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 517\u001B[1;33m       \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    518\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    519\u001B[0m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_self_setattr_tracking\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mprevious_value\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\github\\automlpy\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001B[0m in \u001B[0;36madd\u001B[1;34m(self, layer)\u001B[0m\n\u001B[0;32m    221\u001B[0m       \u001B[1;31m# If the model is being built continuously on top of an input layer:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    222\u001B[0m       \u001B[1;31m# refresh its output.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 223\u001B[1;33m       \u001B[0moutput_tensor\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlayer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moutputs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    224\u001B[0m       \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnest\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mflatten\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutput_tensor\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    225\u001B[0m         \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\github\\automlpy\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    949\u001B[0m     \u001B[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    950\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0m_in_functional_construction_mode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_list\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 951\u001B[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001B[0m\u001B[0;32m    952\u001B[0m                                                 input_list)\n\u001B[0;32m    953\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\github\\automlpy\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001B[0m in \u001B[0;36m_functional_construction_call\u001B[1;34m(self, inputs, args, kwargs, input_list)\u001B[0m\n\u001B[0;32m   1088\u001B[0m           layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001B[0;32m   1089\u001B[0m         \u001B[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1090\u001B[1;33m         outputs = self._keras_tensor_symbolic_call(\n\u001B[0m\u001B[0;32m   1091\u001B[0m             inputs, input_masks, args, kwargs)\n\u001B[0;32m   1092\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\github\\automlpy\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001B[0m in \u001B[0;36m_keras_tensor_symbolic_call\u001B[1;34m(self, inputs, input_masks, args, kwargs)\u001B[0m\n\u001B[0;32m    820\u001B[0m       \u001B[1;32mreturn\u001B[0m \u001B[0mnest\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmap_structure\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkeras_tensor\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mKerasTensor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutput_signature\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    821\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 822\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_infer_output_signature\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_masks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    823\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    824\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0m_infer_output_signature\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_masks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\github\\automlpy\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001B[0m in \u001B[0;36m_infer_output_signature\u001B[1;34m(self, inputs, args, kwargs, input_masks)\u001B[0m\n\u001B[0;32m    861\u001B[0m           \u001B[1;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    862\u001B[0m           \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_maybe_build\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 863\u001B[1;33m           \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    864\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    865\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_handle_activity_regularization\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\github\\automlpy\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\pooling.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, inputs)\u001B[0m\n\u001B[0;32m    293\u001B[0m       \u001B[0mpool_shape\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpool_size\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    294\u001B[0m       \u001B[0mstrides\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstrides\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 295\u001B[1;33m     outputs = self.pool_function(\n\u001B[0m\u001B[0;32m    296\u001B[0m         \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    297\u001B[0m         \u001B[0mksize\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mpool_shape\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\github\\automlpy\\venv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    199\u001B[0m     \u001B[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    200\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 201\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    202\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    203\u001B[0m       \u001B[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\github\\automlpy\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001B[0m in \u001B[0;36mmax_pool\u001B[1;34m(value, ksize, strides, padding, data_format, name, input)\u001B[0m\n\u001B[0;32m   4604\u001B[0m       \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"ksize cannot be zero.\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4605\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 4606\u001B[1;33m     return gen_nn_ops.max_pool(\n\u001B[0m\u001B[0;32m   4607\u001B[0m         \u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4608\u001B[0m         \u001B[0mksize\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mksize\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\github\\automlpy\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001B[0m in \u001B[0;36mmax_pool\u001B[1;34m(input, ksize, strides, padding, explicit_paddings, data_format, name)\u001B[0m\n\u001B[0;32m   5324\u001B[0m     \u001B[0mdata_format\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"NHWC\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5325\u001B[0m   \u001B[0mdata_format\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_execute\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmake_str\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata_format\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"data_format\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 5326\u001B[1;33m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001B[0m\u001B[0;32m   5327\u001B[0m         \u001B[1;34m\"MaxPool\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mksize\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mksize\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstrides\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstrides\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpadding\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mpadding\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5328\u001B[0m                    \u001B[0mexplicit_paddings\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mexplicit_paddings\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\github\\automlpy\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001B[0m in \u001B[0;36m_apply_op_helper\u001B[1;34m(op_type_name, name, **keywords)\u001B[0m\n\u001B[0;32m    746\u001B[0m       \u001B[1;31m# Add Op to graph\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    747\u001B[0m       \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 748\u001B[1;33m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001B[0m\u001B[0;32m    749\u001B[0m                                  \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mscope\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_types\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minput_types\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    750\u001B[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001B[1;32md:\\github\\automlpy\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001B[0m in \u001B[0;36m_create_op_internal\u001B[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001B[0m\n\u001B[0;32m    588\u001B[0m       \u001B[0minp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcapture\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minp\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    589\u001B[0m       \u001B[0mcaptured_inputs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minp\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 590\u001B[1;33m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001B[0m\u001B[0;32m    591\u001B[0m         \u001B[0mop_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcaptured_inputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtypes\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_types\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mattrs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mop_def\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    592\u001B[0m         compute_device)\n",
      "\u001B[1;32md:\\github\\automlpy\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001B[0m in \u001B[0;36m_create_op_internal\u001B[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001B[0m\n\u001B[0;32m   3526\u001B[0m     \u001B[1;31m# Session.run call cannot occur between creating and mutating the op.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3527\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_mutation_lock\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3528\u001B[1;33m       ret = Operation(\n\u001B[0m\u001B[0;32m   3529\u001B[0m           \u001B[0mnode_def\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3530\u001B[0m           \u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\github\\automlpy\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001B[0m\n\u001B[0;32m   2013\u001B[0m       \u001B[1;32mif\u001B[0m \u001B[0mop_def\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2014\u001B[0m         \u001B[0mop_def\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_graph\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_op_def\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnode_def\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mop\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2015\u001B[1;33m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001B[0m\u001B[0;32m   2016\u001B[0m                                 control_input_ops, op_def)\n\u001B[0;32m   2017\u001B[0m       \u001B[0mname\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcompat\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mas_str\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnode_def\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\github\\automlpy\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001B[0m in \u001B[0;36m_create_c_op\u001B[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001B[0m\n\u001B[0;32m   1854\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mInvalidArgumentError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1855\u001B[0m     \u001B[1;31m# Convert to ValueError for backwards compatibility.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1856\u001B[1;33m     \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1857\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1858\u001B[0m   \u001B[1;32mreturn\u001B[0m \u001B[0mc_op\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,28,10]."
     ]
    }
   ],
   "source": [
    "mnist_train, mnist_test = get_tf_mnist_dataset()\n",
    "\n",
    "mnist_hp_optimizer = KerasMNISTHpOptimizer()\n",
    "\n",
    "hp_space = dict(\n",
    "    epochs=list(range(1, 16)),\n",
    "    learning_rate=np.linspace(1e-4, 1e-1, 50),\n",
    "    nesterov=[True, False],\n",
    "    momentum=np.linspace(0.01, 0.99, 50),\n",
    "    use_conv=[True, False],\n",
    ")\n",
    "param_gen = RandomHpSearch(hp_space, max_seconds=60*1, max_itr=1_000)\n",
    "\n",
    "save_kwargs = dict(\n",
    "    save_name=f\"tf_mnist_hp_opt\",\n",
    "    title=\"Random search: MNIST\",\n",
    ")\n",
    "\n",
    "param_gen = mnist_hp_optimizer.optimize_on_dataset(\n",
    "    param_gen, mnist_train, save_kwargs=save_kwargs,\n",
    ")\n",
    "\n",
    "opt_hp = param_gen.get_best_param()\n",
    "\n",
    "model = mnist_hp_optimizer.build_model(**opt_hp)\n",
    "mnist_hp_optimizer.fit_dataset_model_(\n",
    "    model, mnist_train, **opt_hp\n",
    ")\n",
    "\n",
    "test_acc, _ = mnist_hp_optimizer.score_on_dataset(\n",
    "    model, mnist_test, **opt_hp\n",
    ")\n",
    "\n",
    "param_gen.write_optimization_to_html(show=True, **save_kwargs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}